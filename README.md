# Virtual AI Spotter

![Status](https://img.shields.io/badge/Status-Optimized_Beta-green)
![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![License](https://img.shields.io/badge/License-AGPL_v3-blue.svg)
![Coverage](https://img.shields.io/badge/Tests-Passing-brightgreen)

> ğŸš€ **Major Update**: The core engine has been refactored for **Production Readiness**.
> Full rewrite around **FSM-based counting** (debouncing + hysteresis), a **modular Feedback System**, **One Euro Filter** signal smoothing, and a **pure-math Geometry Engine** (zero NumPy overhead).
> Architecture highlights: Factory + Registry extensibility, Protocol-based DI, Session Manager with set/rest orchestration, hands-free **Gesture Control**, **i18n** (IT/EN), **SQLite** persistence, and an optimized **HUD** with ROI alpha blending â€” all validated by a **136-test suite** running at **30+ FPS on CPU**.

## Project Overview
**Virtual AI Spotter** is a real-time Computer Vision assistant designed to act as an intelligent personal trainer. It utilizes state-of-the-art Deep Learning and geometric analysis to provide automatic repetition counting, exercise suggestions, and instant feedback on execution form.

## Technology Stack
- **Core AI**: ![YOLOv8](https://img.shields.io/badge/YOLOv8-Deep_Learning-blue) YOLOv8 (Pose Estimation)
- **Framework**: ![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?logo=PyTorch&logoColor=white) PyTorch
- **Computer Vision**: ![OpenCV](https://img.shields.io/badge/OpenCV-white.svg?logo=opencv&logoColor=black) OpenCV
- **Logic**: ğŸ“ Geometric Vector Analysis & âš™ï¸ Finite State Machines (FSM)
- **Cloud**: ![AWS](https://img.shields.io/badge/AWS-%23FF9900.svg?logo=amazon-aws&logoColor=white) AWS (Lambda, DynamoDB, S3)
- **Database**: ![SQLite](https://img.shields.io/badge/sqlite-%2307405e.svg?logo=sqlite&logoColor=white) ![DynamoDB](https://img.shields.io/badge/Amazon%20DynamoDB-4053D6?logo=amazon-dynamodb&logoColor=white) SQLite (Local), DynamoDB (Cloud)

## Key Features
- **Real-time Pose Estimation**: High-speed, accurate body tracking using YOLOv8-pose.
- **Action Classification**: Distinguishes between different exercises and movement phases.
- **Automatic Rep Counting**: Precision counting based on **Finite State Machines (FSM)** with debouncing and hysteresis.
- **Form Correction**: Instant feedback on posture (e.g., "Lower your hips", "Straighten back") using a modular **Feedback System**.
- **Multi-language Support**: Fully localized interface (Italian/English) with dynamic switching.
- **High-Performance HUD**: Optimized Visualizer engine using ROI-based Alpha Blending for smooth, transparent overlays.
- **Gesture Control**: Hands-free interaction using pose-based gestures (e.g., raised arm to skip rest periods).
- **Extensible Architecture**: Factory + Registry Pattern enables adding new exercises without modifying core code. Dependency Injection via Python Protocols for testability.

## MVP Scope (Minimum Viable Product)
The initial release focuses on 4 fundamental exercises that test different aspects of the tracking engine:

1.  **Squat (Lower Body)**
    *   *Focus*: Knee and hip angles.
    *   *Logic*: Standard FSM (Down < Threshold, Up > Threshold).
    *   *Feedback*: Squat depth and back alignment.

2.  **Push-up (Upper Body)**
    *   *Focus*: Body alignment and elbow extension.
    *   *Challenges*: Robustness against occlusion (body close to floor).
    *   *Feedback*: "Keep back straight" via body angle analysis.

3.  **Bicep Curl (Isolation)**
    *   *Focus*: Elbow flexion/extension.
    *   *Logic*: Inverted FSM Logic (Up/Flexion < Threshold, Down/Extension > Threshold).
    *   *Feedback*: Full extension check.

4.  **Plank (Static Core)**
    *   *Focus*: Maintaining a straight line (Shoulder-Hip-Ankle alignment).
    *   *Logic*: `StaticDurationCounter` FSM with countdown, active timer, and form break detection.

## System Architecture

The project follows a **Layered Architecture** with clear separation of concerns, enabling testability, extensibility (Open/Closed Principle), and adherence to Domain-Driven Design (DDD) principles.

### Data Flow Diagram

```mermaid
%%{init: {'theme': 'neutral'}}%%
graph LR
    subgraph INFRA["ğŸ”Œ Infrastructure Layer"]
        direction TB
        A["ğŸ“· Webcam"] --> B["ğŸ¤– YOLOv8 Pose"]
        B --> C["ğŸ”‘ Keypoint Extractor"]
    end

    subgraph CORE["âš¡ Core Domain"]
        direction TB
        D["ğŸ“ Geometry Engine"] --> E["âš™ï¸ FSM"]
        E --> F["ğŸ’¬ Feedback"]
    end

    subgraph UI["ğŸ¨ Presentation Layer"]
        direction TB
        G["ğŸ–¥ï¸ Visualizer"] --> H["ğŸ“Š Renderers"]
    end

    C ==> D
    F ==> G

    %% Layer styling - pastel fills, semantic strokes
    style INFRA fill:#f3f4f6,stroke:#6b7280,stroke-width:2px,color:#374151
    style CORE fill:#eff6ff,stroke:#3b82f6,stroke-width:2px,color:#1e40af
    style UI fill:#f5f3ff,stroke:#8b5cf6,stroke-width:2px,color:#5b21b6

    %% Node styling - light backgrounds, dark text
    style A fill:#ffffff,stroke:#9ca3af,stroke-width:1px,color:#1f2937
    style B fill:#ffffff,stroke:#9ca3af,stroke-width:1px,color:#1f2937
    style C fill:#ffffff,stroke:#9ca3af,stroke-width:1px,color:#1f2937
    style D fill:#ffffff,stroke:#60a5fa,stroke-width:1px,color:#1e3a8a
    style E fill:#ffffff,stroke:#60a5fa,stroke-width:1px,color:#1e3a8a
    style F fill:#ffffff,stroke:#60a5fa,stroke-width:1px,color:#1e3a8a
    style G fill:#ffffff,stroke:#a78bfa,stroke-width:1px,color:#4c1d95
    style H fill:#ffffff,stroke:#a78bfa,stroke-width:1px,color:#4c1d95

    linkStyle default stroke:#64748b,stroke-width:1px
    linkStyle 3 stroke:#059669,stroke-width:2px
    linkStyle 4 stroke:#059669,stroke-width:2px
```

### 1. Core Domain (`src/core`)

Business logic is fully isolated from external dependencies:

*   **Entities** (`src/core/entities/`): Domain objects following DDD â€” `Session`, `User`, `WorkoutState`, `UIState`.
*   **FSM Core** (`fsm.py`): Reusable `RepetitionCounter` with debouncing, hysteresis, and support for standard/inverted logic.
*   **Feedback System** (`feedback.py`): Aggregates form-check rules and prioritizes messages.
*   **Factory + Registry** (`factory.py`, `registry.py`): Exercises self-register via `@register_exercise` decorator â€” no if/elif chains.
*   **Session Manager** (`session_manager.py`): Orchestrates workout flow, rest periods, and set progression.
*   **Dependency Injection**: Abstractions defined in `protocols.py` (PoseDetector, KeypointExtractor, DatabaseManagerProtocol) enable mock injection for CI/CD testing.

### 2. Infrastructure Layer (`src/infrastructure`)

Handles external integrations, decoupled from business logic:

*   **AI Inference** (`ai_inference.py`): YOLO model wrapper implementing `PoseDetector` protocol.
*   **Keypoint Extractor** (`keypoint_extractor.py`): Transforms raw YOLO output to standardized 17Ã—3 arrays.
*   **Webcam** (`webcam.py`): Frame capture abstraction for easy replacement with video files or streams.

### 3. UI & Visualization (`src/ui`)

Presentation layer with separated rendering responsibilities:

*   **Visualizer** (`visualizer.py`): Facade coordinating all renderers.
*   **Dashboard Renderer**: Draws HUD panels (reps, sets, feedback text).
*   **Overlay Renderer**: Transparent overlays using ROI-based alpha blending.
*   **Skeleton Renderer**: Draws pose skeleton connections.

### 4. Signal Processing (`src/utils`)

*   **Geometry Engine** (`geometry.py`): Pure `math`-based vector calculations (no NumPy overhead).
*   **Smoothing** (`smoothing.py`): One Euro Filter for jitter reduction.
*   **Circular Buffer**: `collections.deque` for temporal smoothing (30-frame window).

### 5. Hybrid Cloud Architecture

*   **Edge**: Real-time inference on local PC/GPU for zero-latency feedback.
*   **Cloud (AWS)**: Planned async sync to DynamoDB/S3 via Lambda.

### 6. Quality Assurance

*   **Test Suite** (`tests/`): 136 automated tests across 13 test files â€” FSM, Geometry, SessionManager, Gesture Detection, DI mocks, exercise integration, and state display coverage.
*   **Verification Scripts**: Manual validation tools for debouncing, i18n, refactoring.

---

<details>
<summary>ğŸ“‚ <strong>View Project Structure (File Tree)</strong></summary>

```
â”œâ”€â”€ ğŸ“ .github
â”‚   â””â”€â”€ ğŸ“ workflows                          # CI/CD pipeline definitions
â”œâ”€â”€ ğŸ“ assets
â”‚   â””â”€â”€ ğŸ“ models
â”‚       â””â”€â”€ ğŸ“„ yolov8n-pose.pt                 # Pre-trained YOLOv8 pose model
â”œâ”€â”€ ğŸ“ config
â”‚   â”œâ”€â”€ ğŸ settings.py                         # Global constants, thresholds, colors
â”‚   â””â”€â”€ ğŸ translation_strings.py              # i18n strings (IT/EN)
â”œâ”€â”€ ğŸ“ scripts
â”‚   â”œâ”€â”€ ğŸ check_cam.py                        # Camera connectivity check
â”‚   â””â”€â”€ ğŸ verify_refactor.py                  # Post-refactor sanity checks
â”œâ”€â”€ ğŸ“ src
â”‚   â”œâ”€â”€ ğŸ“ core                                # Business logic (framework-agnostic)
â”‚   â”‚   â”œâ”€â”€ ğŸ“ entities                        # Domain objects (DDD)
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ session.py                  # Workout session dataclass
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ ui_state.py                 # Rendering state container
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ user.py                     # User profile dataclass
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ workout_state.py            # Workout FSM states (ACTIVE/REST/FINISHED)
â”‚   â”‚   â”œâ”€â”€ ğŸ app.py                          # Composition root & main loop
â”‚   â”‚   â”œâ”€â”€ ğŸ config_types.py                 # TypedDict definitions for configs
â”‚   â”‚   â”œâ”€â”€ ğŸ exceptions.py                   # Custom exception hierarchy (SpotterError)
â”‚   â”‚   â”œâ”€â”€ ğŸ factory.py                      # Exercise factory (creates instances)
â”‚   â”‚   â”œâ”€â”€ ğŸ feedback.py                     # Rule-based form correction engine
â”‚   â”‚   â”œâ”€â”€ ğŸ fsm.py                          # RepetitionCounter & StaticDurationCounter
â”‚   â”‚   â”œâ”€â”€ ğŸ gesture_detector.py             # Pose-based gesture recognition
â”‚   â”‚   â”œâ”€â”€ ğŸ interfaces.py                   # ABCs: Exercise, VideoSource, StateDisplayInfo
â”‚   â”‚   â”œâ”€â”€ ğŸ protocols.py                    # DI protocols: PoseDetector, DBManager
â”‚   â”‚   â”œâ”€â”€ ğŸ registry.py                     # @register_exercise decorator & registry
â”‚   â”‚   â””â”€â”€ ğŸ session_manager.py              # Set/rest/rep orchestration
â”‚   â”œâ”€â”€ ğŸ“ data                                # Persistence layer
â”‚   â”‚   â”œâ”€â”€ ğŸ db_manager.py                   # SQLite CRUD operations
â”‚   â”‚   â””â”€â”€ ğŸ“„ schema.sql                      # Database schema definition
â”‚   â”œâ”€â”€ ğŸ“ exercises                           # Concrete exercise implementations
â”‚   â”‚   â”œâ”€â”€ ğŸ __init__.py                     # Auto-imports for registration
â”‚   â”‚   â”œâ”€â”€ ğŸ curl.py                         # Bicep Curl (inverted FSM)
â”‚   â”‚   â”œâ”€â”€ ğŸ plank.py                        # Plank (static hold timer)
â”‚   â”‚   â”œâ”€â”€ ğŸ pushup.py                       # Push-Up (bilateral + form check)
â”‚   â”‚   â””â”€â”€ ğŸ squat.py                        # Squat (standard FSM)
â”‚   â”œâ”€â”€ ğŸ“ infrastructure                      # External system adapters
â”‚   â”‚   â”œâ”€â”€ ğŸ ai_inference.py                 # YOLO model wrapper (PoseDetector)
â”‚   â”‚   â”œâ”€â”€ ğŸ keypoint_extractor.py           # Raw YOLO output â†’ 17Ã—3 arrays
â”‚   â”‚   â””â”€â”€ ğŸ webcam.py                       # OpenCV camera capture (VideoSource)
â”‚   â”œâ”€â”€ ğŸ“ ui                                  # Presentation layer
â”‚   â”‚   â”œâ”€â”€ ğŸ cli.py                          # Interactive workout setup prompts
â”‚   â”‚   â”œâ”€â”€ ğŸ dashboard_renderer.py           # HUD panel (reps, sets, state)
â”‚   â”‚   â”œâ”€â”€ ğŸ overlay_renderer.py             # Full-screen REST/FINISHED overlays
â”‚   â”‚   â”œâ”€â”€ ğŸ skeleton_renderer.py            # Pose skeleton & angle arcs
â”‚   â”‚   â””â”€â”€ ğŸ visualizer.py                   # Renderer facade (delegates to above)
â”‚   â””â”€â”€ ğŸ“ utils                               # Signal processing utilities
â”‚       â”œâ”€â”€ ğŸ geometry.py                     # Pure-math angle calculations
â”‚       â”œâ”€â”€ ğŸ performance.py                  # FPS counter & timing helpers
â”‚       â””â”€â”€ ğŸ smoothing.py                    # One Euro Filter for jitter reduction
â”œâ”€â”€ ğŸ“ tests                                   # Automated test suite (136 tests)
â”‚   â”œâ”€â”€ ğŸ“ mocks                               # Test doubles
â”‚   â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ mock_pose.py                    # Fake PoseDetector for DI tests
â”‚   â”‚   â””â”€â”€ ğŸ mock_video.py                   # Fake VideoSource for DI tests
â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”œâ”€â”€ ğŸ helpers.py                          # Shared fixtures (UIState, dummy frames)
â”‚   â”œâ”€â”€ ğŸ test_app_di.py                      # Dependency injection wiring tests
â”‚   â”œâ”€â”€ ğŸ test_db_manual.py                   # SQLite persistence tests
â”‚   â”œâ”€â”€ ğŸ test_entities_manual.py             # Domain entity tests
â”‚   â”œâ”€â”€ ğŸ test_exercise_integration.py        # End-to-end rep counting & form feedback
â”‚   â”œâ”€â”€ ğŸ test_exercises.py                   # Exercise process_frame unit tests
â”‚   â”œâ”€â”€ ğŸ test_fsm.py                         # FSM state transitions & debouncing
â”‚   â”œâ”€â”€ ğŸ test_geometry.py                    # Angle calculation edge cases
â”‚   â”œâ”€â”€ ğŸ test_gesture.py                     # Gesture recognition tests
â”‚   â”œâ”€â”€ ğŸ test_plank.py                       # Plank lifecycle & timer tests
â”‚   â”œâ”€â”€ ğŸ test_pose_estimator.py              # PoseEstimator protocol tests
â”‚   â”œâ”€â”€ ğŸ test_session_manager.py             # Workout flow & state transitions
â”‚   â”œâ”€â”€ ğŸ test_smoothing.py                   # One Euro Filter convergence tests
â”‚   â”œâ”€â”€ ğŸ test_visualizer.py                  # Renderer + state display mapping tests
â”‚   â”œâ”€â”€ ğŸ verify_debouncing.py                # Manual debouncing validation
â”‚   â”œâ”€â”€ ğŸ verify_features.py                  # Manual feature smoke tests
â”‚   â”œâ”€â”€ ğŸ verify_i18n.py                      # Manual i18n string verification
â”‚   â””â”€â”€ ğŸ verify_refactor.py                  # Manual refactor validation
â”œâ”€â”€ âš™ï¸ .gitignore
â”œâ”€â”€ ğŸ“„ LICENSE                                  # AGPL v3
â”œâ”€â”€ ğŸ“ README.md
â”œâ”€â”€ ğŸ main.py                                 # Application entry point
â””â”€â”€ ğŸ“„ requirements.txt                        # Python dependencies
```

</details>

---

## ğŸ—ºï¸ Roadmap

- [x] **Project Initialization**
    - [x] Architecture & Tech Stack Definition
    - [x] Repository Structure & `.gitignore`
- [x] **Core Engineering**
    - [x] Abstract `Exercise` Class
    - [x] YOLOv8 Integration
    - [x] **FSM & Feedback Architecture Refactoring**
    - [x] **Performance Optimization (Math + ROI Visualizer)**
- [x] **Exercise Logic (MVP)**
    - [x] Squat (Depth & Form)
    - [x] Push-up (Occlusion handling)
    - [x] Bicep Curl (Inverted Logic)
    - [x] Plank (Static stability check)
- [ ] **Cloud & DevOps**
    - [ ] AWS Lambda & DynamoDB implementation details
    - [x] Unit Testing Suite (`tests/`)
    - [ ] CI/CD Pipeline (GitHub Actions)
